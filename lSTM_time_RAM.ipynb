{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file <ipython-input-14-4de328e5ea4b>\n",
      "NOTE: %mprun can only be used on functions defined in physical files, and not in the IPython environment.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4de328e5ea4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;31m# starttime = timeit.default_timer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;31m# print(\"The start time is :\",starttime)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m \u001b[0mlstmTimePredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;31m# print(\"The time difference is :\", timeit.default_timer() - starttime)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\memory_profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[0mprof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_prof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m                 \u001b[0mshow_results_bound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\memory_profiler.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_ctxmgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-4de328e5ea4b>\u001b[0m in \u001b[0;36mlstmTimePredictor\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mdataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"day\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataSet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"event time:timestamp\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0meventStartHour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_training\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[0meventDay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_training\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mdf_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeToNextEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_training\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from training.lstmTimePrediction import lstmTimePredictor\n",
    "from memory_profiler import profile\n",
    "import timeit\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import datetime as dt\n",
    "\n",
    "@profile(precision=4) #place profile before the function, this will return memory use when running the function\n",
    "def lstmTimePredictor():\n",
    "\n",
    "    df_training = pd.read_csv('./data/BPI2012Training.csv')\n",
    "    df_test = pd.read_csv('./data/BPI2012Test.csv')\n",
    "\n",
    "    # Function that parses the incoming data set\n",
    "    def parseData(dataSet):\n",
    "        # Parse time zone if there are any\n",
    "        def convertToUnix(x):\n",
    "            # If there is a timezone in the timestamp\n",
    "            if 'T' in x:\n",
    "                # Remove the T\n",
    "                without_timezone = x[:10] + ' ' + x[11:-6]\n",
    "\n",
    "                # Parse milliseconds if contained\n",
    "                if '.' in x:\n",
    "                    wholesomeTime = dt.datetime.timestamp(\n",
    "                        dt.datetime.strptime(without_timezone, \"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "                else:\n",
    "                    wholesomeTime = dt.datetime.timestamp(\n",
    "                        dt.datetime.strptime(without_timezone, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "            else:\n",
    "                if '.' in x:\n",
    "                    wholesomeTime = dt.datetime.timestamp(\n",
    "                        dt.datetime.strptime(x, \"%d-%m-%Y %H:%M:%S.%f\"))\n",
    "                else:\n",
    "                    wholesomeTime = dt.datetime.timestamp(\n",
    "                        dt.datetime.strptime(x, \"%d-%m-%Y %H:%M:%S\"))\n",
    "\n",
    "            return wholesomeTime\n",
    "\n",
    "        # Convert absolute event and reg timestamp into unix time\n",
    "        dataSet['unix_abs_event_time'] = dataSet['event time:timestamp'].apply(\n",
    "            lambda x: convertToUnix(x))\n",
    "        dataSet['unix_reg_time'] = dataSet['case REG_DATE'].apply(\n",
    "            lambda x: convertToUnix(x))\n",
    "\n",
    "        # Time it takes for an event to occur from registeration\n",
    "        dataSet['unix_rel_event_time'] = dataSet['unix_abs_event_time'] - \\\n",
    "            dataSet['unix_reg_time']\n",
    "\n",
    "        # Group data set by case ID\n",
    "        dataSet_grouped_by_case = dataSet.groupby(by=['case concept:name'])\n",
    "\n",
    "        # Return data frame consisting out of the last event per case with column that indicates the number of events the case underwent appended\n",
    "        dataSet_last_event_per_case = dataSet_grouped_by_case.nth([-1])\n",
    "        dataSet_last_event_per_case['num_events'] = dataSet_grouped_by_case.count(\n",
    "        ).iloc[:, 0]\n",
    "\n",
    "        return (dataSet, dataSet_last_event_per_case)\n",
    "\n",
    "    def timeToNextEvent(dataSet):\n",
    "        df_predicted_time_to_next_event = dataSet.copy().sort_values(\n",
    "            by=['case concept:name', \"eventID \", \"unix_abs_event_time\"])\n",
    "\n",
    "        unique_events = df_predicted_time_to_next_event[\"event concept:name\"].unique(\n",
    "        )\n",
    "\n",
    "        df_new = df_predicted_time_to_next_event[[\n",
    "            \"actual_time_to_next_event\", \"unix_abs_event_time\", \"unix_rel_event_time\", \"hour\", \"day\"]]\n",
    "\n",
    "        for x in unique_events:\n",
    "            df_new[x] = np.where(\n",
    "                (df_predicted_time_to_next_event[\"event concept:name\"] == x), 1, 0)\n",
    "\n",
    "        return (df_new)\n",
    "\n",
    "    def eventStartHour(dataSet):\n",
    "        dataSet[\"hour\"] = pd.to_datetime(\n",
    "            dataSet[\"event time:timestamp\"]).dt.hour\n",
    "\n",
    "    def eventDay(dataSet):\n",
    "        dataSet[\"day\"] = pd.to_datetime(dataSet[\"event time:timestamp\"]).dt.day\n",
    "\n",
    "    eventStartHour(df_training[0])\n",
    "    eventDay(df_training[0])\n",
    "    df_training = timeToNextEvent(df_training[0])\n",
    "    df_training[\"finished\"] = np.where(\n",
    "        (np.isnan(df_training[\"actual_time_to_next_event\"])), 1, 0)\n",
    "    df_training[\"actual_time_to_next_event\"] = np.where((np.isnan(\n",
    "        df_training[\"actual_time_to_next_event\"])), 0, df_training[\"actual_time_to_next_event\"])\n",
    "\n",
    "    eventStartHour(df_test[0])\n",
    "    eventDay(df_test[0])\n",
    "    df_test = timeToNextEvent(df_test[0])\n",
    "    df_test[\"finished\"] = np.where(\n",
    "        (np.isnan(df_test[\"actual_time_to_next_event\"])), 1, 0)\n",
    "    df_test[\"actual_time_to_next_event\"] = np.where((np.isnan(\n",
    "        df_test[\"actual_time_to_next_event\"])), 0, df_test[\"actual_time_to_next_event\"])\n",
    "\n",
    "    df_test[\"W_Wijzigen contractgegevens\"] = 0\n",
    "\n",
    "    def quick(fini):\n",
    "        fini[\"no_event\"] = 0\n",
    "        arrti = []\n",
    "        counterquick = 0\n",
    "        for x in fini:\n",
    "            arrti.append(counterquick)\n",
    "            if (x == 0):\n",
    "                counterquick += 1\n",
    "            else:\n",
    "                counterquick = 0\n",
    "        return arrti[:-1]\n",
    "\n",
    "    # Convert to values using .values\n",
    "    training_val = df_training.to_numpy()\n",
    "    training_val = training_val.astype('float32')\n",
    "    test_val = df_test.to_numpy()\n",
    "    test_val = test_val.astype('float32')\n",
    "\n",
    "    testiii = []\n",
    "    for x in test_val[0:, 0]:\n",
    "        testiii.append([x])\n",
    "\n",
    "    scalerTraining = MinMaxScaler(feature_range=(0, 1))\n",
    "    training_val = scalerTraining.fit_transform(training_val)\n",
    "    scalerTest = MinMaxScaler(feature_range=(0, 1))\n",
    "    test_val = scalerTest.fit_transform(test_val)\n",
    "    scalerTestSingle = MinMaxScaler(feature_range=(0, 1))\n",
    "    testSingle_val = scalerTestSingle.fit_transform(testiii)\n",
    "\n",
    "    def create_dataset(dataset):\n",
    "        dataX, dataY = [], []\n",
    "        for x in range(0, len(dataset)):\n",
    "            dataX.append(dataset[x: x+1, 1:])\n",
    "            if (np.isnan(dataset[x][0])):\n",
    "                dataY.append(0)\n",
    "            else:\n",
    "                dataY.append(dataset[x][0])\n",
    "\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    x_train, y_train = create_dataset(training_val)\n",
    "    x_test, y_test = create_dataset(test_val)\n",
    "\n",
    "    x_train = np.reshape(\n",
    "        x_train, (x_train.shape[0], x_train.shape[2], x_train.shape[1]))\n",
    "    x_test = np.reshape(\n",
    "        x_test, (x_test.shape[0], x_test.shape[2], x_test.shape[1]))\n",
    "\n",
    "    # Initialising the RNN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units=x_train.shape[2], return_sequences=True, input_shape=(\n",
    "        x_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a second LSTM layer and Dropout layer\n",
    "    model.add(LSTM(units=16, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a third LSTM layer and Dropout layer\n",
    "    model.add(LSTM(units=8, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding a fourth LSTM layer and and Dropout layer\n",
    "    model.add(LSTM(units=3))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adding the output layer\n",
    "    # For Full connection layer we use dense\n",
    "    # As the output is 1D so we use unit=1\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # model.add(LeakyReLU(alpha=0.3))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # compile and fit the model on 30 epochs\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=50, verbose=2)\n",
    "\n",
    "# starttime = timeit.default_timer()\n",
    "# print(\"The start time is :\",starttime)\n",
    "lstmTimePredictor()\n",
    "# print(\"The time difference is :\", timeit.default_timer() - starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
