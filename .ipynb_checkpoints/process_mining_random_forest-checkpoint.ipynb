{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition, datasets\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('.\\data\\BPI2012Training.csv')\n",
    "data_test = pd.read_csv('.\\data\\BPI2012Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(dataSet):\n",
    "    # Parse time zone if there are any\n",
    "    def convertToUnix(x):\n",
    "        # If there is a timezone in the timestamp\n",
    "        if 'T' in x:\n",
    "            # Remove the T\n",
    "            without_timezone = x[:10] + ' ' + x[11:-6]\n",
    "\n",
    "            # Parse milliseconds if contained\n",
    "            if '.' in x:\n",
    "                wholesomeTime = dt.datetime.timestamp(\n",
    "                    dt.datetime.strptime(without_timezone, \"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "            else:\n",
    "                wholesomeTime = dt.datetime.timestamp(\n",
    "                    dt.datetime.strptime(without_timezone, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "        else:\n",
    "            if '.' in x:\n",
    "                wholesomeTime = dt.datetime.timestamp(\n",
    "                    dt.datetime.strptime(x, \"%d-%m-%Y %H:%M:%S.%f\"))\n",
    "            else:\n",
    "                wholesomeTime = dt.datetime.timestamp(\n",
    "                    dt.datetime.strptime(x, \"%d-%m-%Y %H:%M:%S\"))\n",
    "\n",
    "        return wholesomeTime\n",
    "\n",
    "    # Convert absolute event and reg timestamp into unix time\n",
    "    dataSet['unix_abs_event_time'] = dataSet['event time:timestamp'].apply(\n",
    "        lambda x: convertToUnix(x))\n",
    "    dataSet['unix_reg_time'] = dataSet['case REG_DATE'].apply(\n",
    "        lambda x: convertToUnix(x))\n",
    "\n",
    "    # Time it takes for an event to occur from registeration\n",
    "    dataSet['unix_rel_event_time'] = dataSet['unix_abs_event_time'] - \\\n",
    "        dataSet['unix_reg_time']\n",
    "\n",
    "    # Group data set by case ID\n",
    "    dataSet_grouped_by_case = dataSet.groupby(by=['case concept:name'])\n",
    "\n",
    "    # Return data frame consisting out of the last event per case with column that indicates the number of events the case underwent appended\n",
    "    dataSet_last_event_per_case = dataSet_grouped_by_case.nth([-1])\n",
    "    dataSet_last_event_per_case['num_events'] = dataSet_grouped_by_case.count(\n",
    "    ).iloc[:, 0]\n",
    "\n",
    "    return (dataSet, dataSet_last_event_per_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoding(dataSet, attr):\n",
    "    one_hot = pd.get_dummies(dataSet[attr])\n",
    "    df = dataSet.join(one_hot)\n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "\n",
    "def dummy_variables(df):\n",
    "    df_dummy = df\n",
    "\n",
    "    for event_type in df['event concept:name'].unique()[1:]:\n",
    "        df_dummy[event_type] = 0\n",
    "        for event in df_dummy.index:\n",
    "            if df_dummy['event concept:name'][event] == event_type:\n",
    "                df_dummy[event_type][event] = 1\n",
    "\n",
    "    return df_dummy\n",
    "\n",
    "def dummy_trainers(dummy_data):\n",
    "    x1 = dummy_data['A_PARTLYSUBMITTED'][:-1]\n",
    "    x2 = dummy_data['A_PREACCEPTED'][:-1]\n",
    "    x3 = dummy_data['W_Completeren aanvraag'][:-1]\n",
    "    x4 = dummy_data['A_DECLINED'][:-1]\n",
    "    x5 = dummy_data['W_Afhandelen leads'][:-1]\n",
    "    x6 = dummy_data['A_ACCEPTED'][:-1]\n",
    "    x7 = dummy_data['O_SELECTED'][:-1]\n",
    "    x8 = dummy_data['A_FINALIZED'][:-1]\n",
    "    x9 = dummy_data['O_CREATED'][:-1]\n",
    "    x10 = dummy_data['O_SENT'][:-1]\n",
    "    x11 = dummy_data['W_Nabellen offertes'][:-1]\n",
    "    x12 = dummy_data['O_CANCELLED'][:-1]\n",
    "    x13 = dummy_data['A_CANCELLED'][:-1]\n",
    "    x14 = dummy_data['W_Beoordelen fraude'][:-1]\n",
    "    x15 = dummy_data['O_SENT_BACK'][:-1]\n",
    "    x16 = dummy_data['W_Valideren aanvraag'][:-1]\n",
    "    x17 = dummy_data['W_Nabellen incomplete dossiers'][:-1]\n",
    "    x18 = dummy_data['O_ACCEPTED'][:-1]\n",
    "    x19 = dummy_data['A_APPROVED'][:-1]\n",
    "    x20 = dummy_data['A_ACTIVATED'][:-1]\n",
    "    x21 = dummy_data['A_REGISTERED'][:-1]\n",
    "    x22 = dummy_data['O_DECLINED'][:-1]\n",
    "    #x23 = dummy_data['W_Wijzigen contractgegevens'][:-1]\n",
    "    x23 = dummy_data['A_SUBMITTED'][:-1]\n",
    "    x_time = dummy_data['unix_rel_event_time'][1:]\n",
    "    y_train = dummy_data['event concept:name'][1:]\n",
    "\n",
    "    zipped = zip(x_time, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20, x21,\n",
    "                 x22, x23)\n",
    "\n",
    "    X_train =[list(a) for a in zipped]\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "def x_prediction(test_data):\n",
    "    x1 = test_data['A_PARTLYSUBMITTED'][:-1]\n",
    "    x2 = test_data['A_PREACCEPTED'][:-1]\n",
    "    x3 = test_data['W_Completeren aanvraag'][:-1]\n",
    "    x4 = test_data['A_DECLINED'][:-1]\n",
    "    x5 = test_data['W_Afhandelen leads'][:-1]\n",
    "    x6 = test_data['A_ACCEPTED'][:-1]\n",
    "    x7 = test_data['O_SELECTED'][:-1]\n",
    "    x8 = test_data['A_FINALIZED'][:-1]\n",
    "    x9 = test_data['O_CREATED'][:-1]\n",
    "    x10 = test_data['O_SENT'][:-1]\n",
    "    x11 = test_data['W_Nabellen offertes'][:-1]\n",
    "    x12 = test_data['O_CANCELLED'][:-1]\n",
    "    x13 = test_data['A_CANCELLED'][:-1]\n",
    "    x14 = test_data['W_Beoordelen fraude'][:-1]\n",
    "    x15 = test_data['O_SENT_BACK'][:-1]\n",
    "    x16 = test_data['W_Valideren aanvraag'][:-1]\n",
    "    x17 = test_data['W_Nabellen incomplete dossiers'][:-1]\n",
    "    x18 = test_data['O_ACCEPTED'][:-1]\n",
    "    x19 = test_data['A_APPROVED'][:-1]\n",
    "    x20 = test_data['A_ACTIVATED'][:-1]\n",
    "    x21 = test_data['A_REGISTERED'][:-1]\n",
    "    x22 = test_data['O_DECLINED'][:-1]\n",
    "    #x23 = test_data['W_Wijzigen contractgegevens'][:-1]\n",
    "    x23 = test_data['A_SUBMITTED'][:-1]\n",
    "    x_time = test_data['unix_rel_event_time'][1:]\n",
    "    y_train = test_data['event concept:name'][1:]\n",
    "\n",
    "    zipped = zip(x_time, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16, x17, x18, x19, x20, x21,\n",
    "                 x22, x23)\n",
    "\n",
    "    X_test = [list(a) for a in zipped]\n",
    "    return X_test\n",
    "\n",
    "\n",
    "def fit_tree(X, y):\n",
    "    boom = tree.DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=14,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "            splitter='best')\n",
    "\n",
    "    boom.fit(X, y)\n",
    "\n",
    "    return boom\n",
    "\n",
    "#boom = fit_tree(x_train, y_train)\n",
    "\n",
    "def tree_predict(X_test, data, boom):\n",
    "    new_df = data.copy()\n",
    "\n",
    "    predictions = boom.predict(X_test)\n",
    "    predictions1 = np.insert(predictions, 0, 0)\n",
    "    new_df['predictedNextEvent'] = predictions1\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def quick_dummy(dataSet, attr):\n",
    "    one_hot = pd.get_dummies(dataSet[:][attr])\n",
    "    df = dataSet.join(one_hot)\n",
    "\n",
    "    return (df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_forest(X_train, y_train):\n",
    "    bos = RandomForestClassifier(n_estimators = 100)\n",
    "    bos.fit(X_train, y_train)\n",
    "    \n",
    "    return bos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parsed = parseData(data_train)\n",
    "test_parsed = parseData(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = quick_dummy(data_train, 'event concept:name')\n",
    "df_test = quick_dummy(data_test, 'event concept:name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'presort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4ac072fa4029>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#X_validation = x_prediction(df_validation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdecision_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf_Predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f1e027936155>\u001b[0m in \u001b[0;36mfit_tree\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpresort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             splitter='best')\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[0mboom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'presort'"
     ]
    }
   ],
   "source": [
    "X_train, y_train = dummy_trainers(df_train) #current df_training doenst contain dummy variables yet\n",
    "#X_validation = x_prediction(df_validation)\n",
    "X_test = x_prediction(df_test)\n",
    "decision_tree = fit_tree(X_train, y_train)\n",
    "df_Predictions = tree_predict(X_test, df_test, decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = fit_forest(X_train, y_train)\n",
    "df_Predictions_forest = tree_predict(X_test, df_test, forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(df_pred):\n",
    "    acc=0\n",
    "    \n",
    "    for i in df_pred.index:\n",
    "        if df_pred['event concept:name'][i] == df_pred['predictedNextEvent'][i]:\n",
    "            acc += 1\n",
    "            \n",
    "    accuracy = acc/len(df_pred)\n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(df_Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(df_Predictions_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=12,\n",
    "#            max_features=None, max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "#            splitter='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding random forest parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 64, stop = 1640, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 95, num = 9)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [int(x) for x in np.linspace(0, 40, num = 8)]\n",
    "min_samples_split.remove(0)\n",
    "min_samples_split.insert(0, 1)\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [int(x) for x in np.linspace(0, 40, num = 8)]\n",
    "min_samples_split.remove(0)\n",
    "min_samples_split.insert(0, 1)\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 25, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
