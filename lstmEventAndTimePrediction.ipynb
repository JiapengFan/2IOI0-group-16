{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, parse and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from training.predictionAlgo import naiveNextEventPredictor, naiveTimeToNextEventPredictor\n",
    "from preprocessing.dataParsing import parseData\n",
    "from preprocessing.dataSplitting import dataSplitter\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from math import ceil\n",
    "\n",
    "# Convert csv into dataframe\n",
    "df_training_raw = pd.read_csv('.\\data\\BPI2012Training.csv')\n",
    "df_test_raw = pd.read_csv('.\\data\\BPI2012Test.csv')\n",
    "\n",
    "# Parsing data\n",
    "(df_training, df_2012_last_event_per_case_train) = parseData(df_training_raw)\n",
    "(df_test, df_2012_last_event_per_case_test) = parseData(df_test_raw)\n",
    "\n",
    "# Clean and split the data into train, validation & test data\n",
    "(df_training, df_validation, df_test) = dataSplitter(df_training, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input of lstm for event prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eventInputLstm(df, core_features: list, extra_features: list, scaler_encoder: list, window_size: int):\n",
    "    '''\n",
    "    args:\n",
    "    df <class: 'pd.DataFrame'>: Dataframe of interest, filled with the features of arguments.\n",
    "    core_features <class: 'list'>: Column names of the core features in format of [case id, current event, next event].\n",
    "    extra_features <class: 'list'>: Extra features that the user wishes to train on, can be given in any sequences.\n",
    "    scaler_encoder <class: 'list' of 'sklearn.preprocessing.MinMaxScaler' or klearn.preprocessing.OneHotEncoder>: \n",
    "    Trained scaler or encoder associated with the input features by their index that is used to normalise float or int features and encode categorical features.\n",
    "    window_size <class: 'int'>: Window size of lstm input.\n",
    "    \n",
    "    returns:\n",
    "    x_arr <'np.array'>: LSTM input in format [samples, timestep, features].\n",
    "    y_arr <'np.array'>: LSTM input in format [samples, features].\n",
    "    '''\n",
    "    case_id_col = core_features[0]\n",
    "    event_id_col = core_features[1]\n",
    "    y_output_col = core_features[2]\n",
    "    \n",
    "    scaler_encoder_copy = scaler_encoder.copy()\n",
    "    \n",
    "    encoder_events = scaler_encoder_copy.pop(0)\n",
    "    \n",
    "    # Prevent modifying argument\n",
    "    relevant_columns = core_features.copy()\n",
    "    try:\n",
    "        relevant_columns.extend(extra_features)\n",
    "    except:\n",
    "        print('Please input valid features.')\n",
    "    \n",
    "    df_relevant = df[relevant_columns].copy()\n",
    "\n",
    "    # One-hot encode current and next event\n",
    "    current_event = df_relevant[event_id_col].to_numpy().reshape(-1, 1)\n",
    "    df_relevant[event_id_col] = encoder_events.transform(current_event).tolist()\n",
    "\n",
    "    next_event = df_relevant[y_output_col].to_numpy().reshape(-1, 1)\n",
    "    df_relevant[y_output_col] = encoder_events.transform(next_event).tolist()\n",
    "    \n",
    "    # Normalise extra features that are ints or floats\n",
    "    for idx, scaler in enumerate(scaler_encoder_copy):\n",
    "        if scaler != 0:\n",
    "            to_be_normalised = df_relevant[extra_features[idx]].to_numpy().reshape(-1, 1)\n",
    "            df_relevant[extra_features[idx]] = scaler.transform(to_be_normalised)\n",
    "\n",
    "    # Prepare input and output in form of [samples, features]\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    # Get groupby object df by case id\n",
    "    df_groupby_case_id = df_relevant.groupby(case_id_col)\n",
    "\n",
    "    # Unique case ids\n",
    "    unique_case_ids = df_relevant[case_id_col].unique().tolist()\n",
    "\n",
    "    # Find input and output vector in form of [samples, features]\n",
    "    for unique_id in unique_case_ids:\n",
    "        columns_relevant = [event_id_col, y_output_col].copy()\n",
    "        columns_relevant.extend(extra_features)\n",
    "        xy_unique_id = df_groupby_case_id.get_group(unique_id)[columns_relevant].values.tolist()\n",
    "        sequence_x_unique_id = []\n",
    "\n",
    "        # event[0] = current event, event[1] = next event, event[2] = first selected feature, event[3] = second selected feature,...\n",
    "        for idx, event in enumerate(xy_unique_id):\n",
    "            if len(sequence_x_unique_id) == window_size:\n",
    "                del sequence_x_unique_id[0]\n",
    "\n",
    "            event_memory = event[0].copy()\n",
    "            event_memory.extend(event[2:])\n",
    "            sequence_x_unique_id.append(event_memory.copy())\n",
    "            x.append(sequence_x_unique_id.copy())\n",
    "            y.append(event[1])\n",
    "    \n",
    "    # Alter input to [samples, timestep, features] for lstm, zero padding used to equalize timestep length\n",
    "    x_arr = pad_sequences(x, dtype='float32')\n",
    "    \n",
    "    # Convert y to format [samples, features]\n",
    "    y_arr = np.reshape(y, (-1, len(y[0])))\n",
    "\n",
    "    return x_arr, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-e979a21e4cc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mnumber_events_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_events_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meventInputLstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcore_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_events_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meventInputLstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcore_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_events_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meventInputLstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcore_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_scaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_events_mean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-2e59470673af>\u001b[0m in \u001b[0;36meventInputLstm\u001b[1;34m(df, core_features, extra_features, scaler_encoder, window_size)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mcolumns_relevant\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mevent_id_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_output_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mcolumns_relevant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextra_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mxy_unique_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_groupby_case_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns_relevant\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0msequence_x_unique_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3034\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3036\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3597\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3598\u001b[0m         \"\"\"\n\u001b[1;32m-> 3599\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3600\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3601\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3585\u001b[0m         new_data = self._mgr.take(\n\u001b[1;32m-> 3586\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3587\u001b[0m         )\n\u001b[0;32m   3588\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"take\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1473\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m         return self.reindex_indexer(\n\u001b[1;32m-> 1475\u001b[1;33m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1476\u001b[0m         )\n\u001b[0;32m   1477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   1306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m             new_blocks = self._slice_take_blocks_ax0(\n\u001b[1;32m-> 1308\u001b[1;33m                 \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monly_slice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0monly_slice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m             )\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice)\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             blknos = algos.take_1d(\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1390\u001b[0m             )\n\u001b[0;32m   1391\u001b[0m             blklocs = algos.take_1d(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mblknos\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[1;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-keras-gpu\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine actual next event\n",
    "(df_training, df_validation) = naiveNextEventPredictor(df_training, df_validation)\n",
    "(df_training, df_test) = naiveNextEventPredictor(df_training, df_test)\n",
    "\n",
    "current_unique = df_training['event concept:name'].unique()\n",
    "next_unique = df_training['actual_next_event'].unique()\n",
    "unique_training_events = np.append(next_unique, np.setdiff1d(current_unique, next_unique, assume_unique=True)).reshape(-1, 1)\n",
    "\n",
    "# Define One-hot encoder for events\n",
    "onehot_encoder_event = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "onehot_encoder_event = onehot_encoder_event.fit(unique_training_events)\n",
    "\n",
    "# see function comment for format\n",
    "core_features = ['case concept:name', 'event concept:name', 'actual_next_event']\n",
    "\n",
    "# Example with unix_reg_time as extra features\n",
    "extra_features = ['event lifecycle:transition', 'case AMOUNT_REQ']\n",
    "\n",
    "# now determining which feature of the extra features needs to be normalised becomes possible by inspecting the index of scalers list\n",
    "encoder_scaler = [onehot_encoder_event] + [0]*len(extra_features)\n",
    "\n",
    "# Instatiate scalers for features consisting out of the type float or int or encoder for categorical featurees\n",
    "for idx, extra_feature in enumerate(extra_features):\n",
    "    if len(df_training[extra_feature].unique()) < 25:\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        arr_to_be_encoded = df_training[extra_feature].to_numpy().reshape(-1, 1)\n",
    "        encoder = encoder.fit(arr_to_be_encoded)\n",
    "        encoder_scaler[idx + 1] = encoder\n",
    "    else:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        arr_to_be_normalied = df_training[extra_feature].to_numpy().reshape(-1, 1)\n",
    "        scaler = scaler.fit(arr_to_be_normalied)\n",
    "        encoder_scaler[idx + 1] = scaler\n",
    "\n",
    "# window size as the mean of case length\n",
    "number_events_mean = df_training.groupby('case concept:name').count()['event concept:name'].mean()\n",
    "number_events_mean = ceil(number_events_mean)\n",
    "\n",
    "x_train, y_train = eventInputLstm(df_training, core_features, extra_features, encoder_scaler, number_events_mean)\n",
    "x_val, y_val = eventInputLstm(df_validation, core_features, extra_features, encoder_scaler, number_events_mean)\n",
    "x_test, y_test = eventInputLstm(df_test, core_features, extra_features, encoder_scaler, number_events_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input of LSTM for time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeInputLstm(df, core_features: list, extra_features: list, scaler_encoder: list, window_size: int):\n",
    "    '''\n",
    "    args:\n",
    "    df <class: 'pd.DataFrame'>: Dataframe of interest, filled with the features of arguments.\n",
    "    core_features <class: 'list'>: Column names of the core features in format of [case id, current event, time to next event].\n",
    "    extra_features <class: 'list'>: Extra features that the user wishes to train on, can be given in any sequences.\n",
    "    scaler_encoder <class: 'list' of 'sklearn.preprocessing.MinMaxScaler' or klearn.preprocessing.OneHotEncoder>: \n",
    "    Trained scaler or encoder associated with the input features by their index that is used to normalise float or int features and encode categorical features.\n",
    "    window_size <class: 'int'>: Window size of lstm input.\n",
    "    \n",
    "    returns:\n",
    "    x_arr <'np.array'>: LSTM input in format [samples, timestep, features].\n",
    "    y_arr <'np.array'>: LSTM input in format [samples, features].\n",
    "    '''\n",
    "    # See function comment for format\n",
    "    case_id_col = core_features[0]\n",
    "    event_id_col = core_features[1]\n",
    "    y_output_col = core_features[2]\n",
    "    \n",
    "    scaler_encoder_copy = scaler_encoder.copy()\n",
    "    \n",
    "    encoder_events = scaler_encoder_copy.pop(0)\n",
    "\n",
    "    time_to_next_scaler = scaler_encoder_copy.pop(0)\n",
    "    \n",
    "    # Prevent modifying argument\n",
    "    relevant_columns = core_features.copy()\n",
    "    relevant_columns.extend(extra_features)\n",
    "    \n",
    "    try:\n",
    "        df_relevant = df[relevant_columns].copy()\n",
    "    except:\n",
    "        print('Please input valid features.')\n",
    "\n",
    "    # One-hot encode current event\n",
    "    current_event = df_relevant[event_id_col].to_numpy().reshape(-1, 1)\n",
    "    df_relevant[event_id_col] = encoder_events.transform(current_event).tolist()\n",
    "\n",
    "    # Normalise time to next event.\n",
    "    time_to_next_event = df_relevant[y_output_col].to_numpy().reshape(-1, 1)\n",
    "    df_relevant[y_output_col] = time_to_next_scaler.transform(time_to_next_event)\n",
    "    \n",
    "    for idx, scaler_encoder in enumerate(scaler_encoder_copy):\n",
    "            to_be_normalised_or_encoded = df_relevant[extra_features[idx]].to_numpy().reshape(-1, 1)\n",
    "            df_relevant[extra_features[idx]] = scaler_encoder.transform(to_be_normalised_or_encoded)\n",
    "\n",
    "    # Prepare input and output in form of [samples, features]\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    # Get groupby object df by case id\n",
    "    df_groupby_case_id = df_relevant.groupby(case_id_col)\n",
    "\n",
    "    # Unique case ids\n",
    "    unique_case_ids = df_relevant[case_id_col].unique().tolist()\n",
    "    \n",
    "    # Remove case id out of relevant columns\n",
    "    del relevant_columns[0]\n",
    "\n",
    "    # Find input and output vector in form of [samples, features]\n",
    "    for unique_id in unique_case_ids:\n",
    "        xy_unique_id = df_groupby_case_id.get_group(unique_id)[relevant_columns].values.tolist()\n",
    "        sequence_x_unique_id = []\n",
    "\n",
    "        # event[0] = current event, event[1] = actual time to next event, event[2] = first selected feature, event[3] = second selected feature,...\n",
    "        for event in xy_unique_id:\n",
    "            if len(sequence_x_unique_id) == number_events_mean:\n",
    "                del sequence_x_unique_id[0]\n",
    "\n",
    "            event_memory = event[0].copy()\n",
    "            event_memory.extend(event[2:])\n",
    "            sequence_x_unique_id.append(event_memory.copy())\n",
    "            x.append(sequence_x_unique_id.copy())\n",
    "            y.append(event[1])\n",
    "    \n",
    "    # Alter input to [samples, timestep, features] for lstm, zero padding used to equalize timestep length\n",
    "    x_arr = pad_sequences(x, dtype='float32')\n",
    "    \n",
    "    # Convert y to format [samples, features]\n",
    "    y_arr = np.reshape(y, (-1, 1))\n",
    "\n",
    "    return x_arr, y_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine time to next event\n",
    "(df_training, df_validation) = naiveTimeToNextEventPredictor(df_training, df_validation)\n",
    "(df_training, df_test) = naiveTimeToNextEventPredictor(df_training, df_test)\n",
    "\n",
    "# Determine actual next event\n",
    "(df_training, df_validation) = naiveNextEventPredictor(df_training, df_validation)\n",
    "(df_training, df_test) = naiveNextEventPredictor(df_training, df_test)\n",
    "\n",
    "# # Define scaler for unix rel event time\n",
    "# rel_event_time_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# rel_event_time = df_training['unix_rel_event_time'].to_numpy().reshape(-1, 1)\n",
    "# rel_event_time_scaler = rel_event_time_scaler.fit(rel_event_time)\n",
    "current_unique = df_training['event concept:name'].unique()\n",
    "next_unique = df_training['actual_next_event'].unique()\n",
    "unique_training_events = np.append(next_unique, np.setdiff1d(current_unique, next_unique, assume_unique=True)).reshape(-1, 1)\n",
    "\n",
    "# Define One-hot encoder for events\n",
    "onehot_encoder_event = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "onehot_encoder_event = onehot_encoder_event.fit(unique_training_events)\n",
    "\n",
    "def eventDay(dataSet):\n",
    "    dataSet[\"day\"] = pd.to_datetime(dataSet[\"event time:timestamp\"]).dt.day\n",
    "def eventStartHour(dataSet):\n",
    "    dataSet[\"hour\"] = pd.to_datetime(dataSet[\"event time:timestamp\"]).dt.hour\n",
    "    \n",
    "eventDay(df_training)\n",
    "eventStartHour(df_training)\n",
    "eventDay(df_validation)\n",
    "eventStartHour(df_validation)\n",
    "eventDay(df_test)\n",
    "eventStartHour(df_test)\n",
    "\n",
    "# Normalise time to next event.\n",
    "# Hard coded column can be replaced as argument\n",
    "time_to_next_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "time_to_next_event = df_training['actual_time_to_next_event'].to_numpy().reshape(-1, 1)\n",
    "time_to_next_scaler = time_to_next_scaler.fit(time_to_next_event)\n",
    "\n",
    "# see function comment for format\n",
    "core_features = ['case concept:name', 'event concept:name', 'actual_time_to_next_event']\n",
    "\n",
    "# Example with unix_reg_time as extra features\n",
    "extra_features = ['day', 'event lifecycle:transition']\n",
    "\n",
    "# now determining which feature of the extra features needs to be normalised becomes possible by inspecting the index of scalers list\n",
    "encoder_scaler = [onehot_encoder_event, time_to_next_scaler] + [0]*len(extra_features)\n",
    "\n",
    "# Instatiate scalers for features consisting out of the type float or int or encoder for categorical featurees\n",
    "for idx, extra_feature in enumerate(extra_features):\n",
    "    if len(df_training[extra_feature].unique()) < 25:\n",
    "        encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "        arr_to_be_encoded = df_training[extra_feature].to_numpy().reshape(-1, 1)\n",
    "        encoder = encoder.fit(arr_to_be_encoded)\n",
    "        encoder_scaler[idx + 2] = encoder\n",
    "    else:\n",
    "        scaler = MinMaxScaler(feature_range=(0,1))\n",
    "        arr_to_be_normalied = df_training[extra_feature].to_numpy().reshape(-1, 1)\n",
    "        scaler = scaler.fit(arr_to_be_normalied)\n",
    "        encoder_scaler[idx + 2] = scaler\n",
    "        \n",
    "# window size as the mean of case length\n",
    "number_events_mean = df_training.groupby('case concept:name').count()['event concept:name'].mean()\n",
    "number_events_mean = ceil(number_events_mean)\n",
    "\n",
    "x_train, y_train = timeInputLstm(df_training, core_features, extra_features, encoder_scaler, number_events_mean)\n",
    "x_val, y_val = timeInputLstm(df_validation, core_features, extra_features, encoder_scaler, number_events_mean)\n",
    "x_test, y_test = timeInputLstm(df_test, core_features, extra_features, encoder_scaler, number_events_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for event prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "CLASS_SIZE = unique_training_events.shape[0]\n",
    "\n",
    "def model_fn(labels_dim):\n",
    "    \"\"\"Create a Keras Sequential model with layers.\"\"\"\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(128,  return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2]), kernel_initializer='glorot_uniform'))\n",
    "    model.add(keras.layers.LayerNormalization())\n",
    "    model.add(keras.layers.LSTM(64, kernel_initializer='glorot_uniform'))\n",
    "    model.add(keras.layers.LayerNormalization())\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "    model.add(keras.layers.Dense(labels_dim, activation='softmax'))\n",
    "    model.summary()\n",
    "    compile_model(model)\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_latest(checkpoint_dir, filetype='.h5', signature='cp', overwrite=False):\n",
    "    \"\"\" \n",
    "        This is a workaround as tf.train.latest_checkpoint does not seem to\n",
    "        work well on codalab. Give preference to that function when possible.\n",
    "\n",
    "        If overwrite is True, the latest checkpoint is reset to 0 and all \n",
    "        others are deleted.\n",
    "    \"\"\"\n",
    "    latest = None\n",
    "    latest_number = -1\n",
    "    for filename in os.listdir(checkpoint_dir):\n",
    "        reference, extension = os.path.splitext(filename)\n",
    "        if extension == filetype and reference.startswith('cp'):\n",
    "            number = int(re.sub(r\"\\D\", \"\", reference))\n",
    "            if number > latest_number:\n",
    "                latest = filename\n",
    "                latest_number = number\n",
    "            else:\n",
    "                if overwrite:\n",
    "                    os.remove(os.path.join(checkpoint_dir, filename))\n",
    "    if latest is None:\n",
    "        raise ValueError('No previous checkpoint found.')\n",
    "    if overwrite:\n",
    "        os.rename(os.path.join(checkpoint_dir, latest), os.path.join(checkpoint_dir, 'cp-0000.h5'))\n",
    "        latest = 'cp-0000.h5'\n",
    "        shutil.rmtree(os.path.join(checkpoint_dir, 'logs')) \n",
    "    return os.path.join(checkpoint_dir, latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "FILE_PATH=\"cp-{epoch:04d}.h5\"\n",
    "LSTM_MODEL = 'lstm.h5'\n",
    "\n",
    "def run(num_epochs=10,  # Maximum number of epochs on which to train\n",
    "        train_batch_size=64,  # Batch size for training steps\n",
    "        job_dir='jobdir_event', # Local dir to write checkpoints and export model\n",
    "        checkpoint_epochs='epoch',  #  Save checkpoint every epoch\n",
    "        removeall=False):\n",
    "\n",
    "    \"\"\" This function trains the model for a number of epochs and returns the \n",
    "        training history. The model is periodically saved for later use.\n",
    "\n",
    "        You can load a pre-trained model with \n",
    "            `model.load_weights(cp_path)`\n",
    "        where `model` is a keras object (e.g. as returned by `model_fn`) and \n",
    "        `cp_path` is the path for the checkpoint you want to load.\n",
    "\n",
    "        Setting load_previous_model to True will remove all training checkpoints.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    try:\n",
    "        os.makedirs(job_dir)\n",
    "    except:\n",
    "        if removeall:\n",
    "            for filename in os.listdir(job_dir):\n",
    "                try:\n",
    "                    os.remove(os.path.join(job_dir, filename))\n",
    "                except:\n",
    "                    shutil.rmtree(os.path.join(job_dir, filename))\n",
    "\n",
    "    checkpoint_path = FILE_PATH\n",
    "    checkpoint_path = os.path.join(job_dir, checkpoint_path)\n",
    "\n",
    "    lstm_model = model_fn(CLASS_SIZE)\n",
    "\n",
    "    # Model checkpoint callback\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        verbose=2,\n",
    "        save_freq=checkpoint_epochs,\n",
    "        mode='max')\n",
    "\n",
    "    # Tensorboard logs callback\n",
    "    tblog = keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(job_dir, 'logs'),\n",
    "        histogram_freq=0,\n",
    "        update_freq='epoch',\n",
    "        write_graph=True,\n",
    "        embeddings_freq=0)\n",
    "\n",
    "    #implemented earlystopping\n",
    "    callbacks = [checkpoint, tblog, keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4)]\n",
    "\n",
    "    history = lstm_model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train, \n",
    "            validation_data = (x_val, y_val),\n",
    "            batch_size=train_batch_size,\n",
    "            steps_per_epoch=None,\n",
    "            epochs=num_epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2)\n",
    "\n",
    "    lstm_model.save(os.path.join(job_dir, LSTM_MODEL))\n",
    "\n",
    "    return history, lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history, lstm_model = run(removeall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM time prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def model_fn():\n",
    "    \"\"\"Create a Keras Sequential model with layers.\"\"\"\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.LSTM(256, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(keras.layers.LayerNormalization())\n",
    "    model.add(keras.layers.Dense(1, activation='linear'))\n",
    "    model.summary()\n",
    "    compile_model(model)\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(loss='mse', \n",
    "                  optimizer=opt,\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "def get_latest(checkpoint_dir, filetype='.h5', signature='cp', overwrite=False):\n",
    "    \"\"\" \n",
    "        This is a workaround as tf.train.latest_checkpoint does not seem to\n",
    "        work well on codalab. Give preference to that function when possible.\n",
    "\n",
    "        If overwrite is True, the latest checkpoint is reset to 0 and all \n",
    "        others are deleted.\n",
    "    \"\"\"\n",
    "    latest = None\n",
    "    latest_number = -1\n",
    "    for filename in os.listdir(checkpoint_dir):\n",
    "        reference, extension = os.path.splitext(filename)\n",
    "        if extension == filetype and reference.startswith('cp'):\n",
    "            number = int(re.sub(r\"\\D\", \"\", reference))\n",
    "            if number > latest_number:\n",
    "                latest = filename\n",
    "                latest_number = number\n",
    "            else:\n",
    "                if overwrite:\n",
    "                    os.remove(os.path.join(checkpoint_dir, filename))\n",
    "    if latest is None:\n",
    "        raise ValueError('No previous checkpoint found.')\n",
    "    if overwrite:\n",
    "        os.rename(os.path.join(checkpoint_dir, latest), os.path.join(checkpoint_dir, 'cp-0000.h5'))\n",
    "        latest = 'cp-0000.h5'\n",
    "        shutil.rmtree(os.path.join(checkpoint_dir, 'logs')) \n",
    "    return os.path.join(checkpoint_dir, latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "FILE_PATH=\"cp-{epoch:04d}.h5\"\n",
    "LSTM_MODEL = 'lstm.h5'\n",
    "\n",
    "def run(num_epochs=10,  # Maximum number of epochs on which to train\n",
    "        train_batch_size=64,  # Batch size for training steps\n",
    "        job_dir='jobdir_time', # Local dir to write checkpoints and export model\n",
    "        checkpoint_epochs='epoch',  #  Save checkpoint every epoch\n",
    "        removeall=False):\n",
    "\n",
    "    \"\"\" This function trains the model for a number of epochs and returns the \n",
    "        training history. The model is periodically saved for later use.\n",
    "\n",
    "        You can load a pre-trained model with \n",
    "            `model.load_weights(cp_path)`\n",
    "        where `model` is a keras object (e.g. as returned by `model_fn`) and \n",
    "        `cp_path` is the path for the checkpoint you want to load.\n",
    "\n",
    "        Setting load_previous_model to True will remove all training checkpoints.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    try:\n",
    "        os.makedirs(job_dir)\n",
    "    except:\n",
    "        if removeall:\n",
    "            for filename in os.listdir(job_dir):\n",
    "                try:\n",
    "                    os.remove(os.path.join(job_dir, filename))\n",
    "                except:\n",
    "                    shutil.rmtree(os.path.join(job_dir, filename))\n",
    "\n",
    "    checkpoint_path = FILE_PATH\n",
    "    checkpoint_path = os.path.join(job_dir, checkpoint_path)\n",
    "\n",
    "    lstm_model = model_fn()\n",
    "\n",
    "    # Model checkpoint callback\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_path,\n",
    "        monitor='val_root_mean_squared_error',\n",
    "        verbose=2,\n",
    "        save_freq=checkpoint_epochs,\n",
    "        mode='max')\n",
    "\n",
    "    # Tensorboard logs callback\n",
    "    tblog = keras.callbacks.TensorBoard(\n",
    "        log_dir=os.path.join(job_dir, 'logs'),\n",
    "        histogram_freq=0,\n",
    "        update_freq='epoch',\n",
    "        write_graph=True,\n",
    "        embeddings_freq=0)\n",
    "\n",
    "    # Implemented early stopping\n",
    "    callbacks = [checkpoint, tblog, keras.callbacks.EarlyStopping(monitor='val_root_mean_squared_error', patience=4)]\n",
    "\n",
    "    history = lstm_model.fit(\n",
    "            x=x_train,\n",
    "            y=y_train, \n",
    "            validation_data = (x_val, y_val),\n",
    "            batch_size=train_batch_size,\n",
    "            steps_per_epoch=None,\n",
    "            epochs=num_epochs,\n",
    "            callbacks=callbacks,\n",
    "            verbose=2)\n",
    "\n",
    "    lstm_model.save(os.path.join(job_dir, LSTM_MODEL))\n",
    "\n",
    "    return history, lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 21, 256)           290816    \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 21, 256)           512       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 488,833\n",
      "Trainable params: 488,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 193367 samples, validate on 21010 samples\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 00001: saving model to jobdir_time\\cp-0001.h5\n",
      "193367/193367 - 32s - loss: 0.0191 - root_mean_squared_error: 0.1383 - val_loss: 2.7682e-04 - val_root_mean_squared_error: 0.0166\n",
      "Epoch 2/10\n",
      "\n",
      "Epoch 00002: saving model to jobdir_time\\cp-0002.h5\n",
      "193367/193367 - 28s - loss: 4.0788e-04 - root_mean_squared_error: 0.0202 - val_loss: 2.2535e-04 - val_root_mean_squared_error: 0.0150\n",
      "Epoch 3/10\n",
      "\n",
      "Epoch 00003: saving model to jobdir_time\\cp-0003.h5\n",
      "193367/193367 - 26s - loss: 3.0037e-04 - root_mean_squared_error: 0.0173 - val_loss: 1.8241e-04 - val_root_mean_squared_error: 0.0135\n",
      "Epoch 4/10\n",
      "\n",
      "Epoch 00004: saving model to jobdir_time\\cp-0004.h5\n",
      "193367/193367 - 27s - loss: 2.4868e-04 - root_mean_squared_error: 0.0158 - val_loss: 1.7555e-04 - val_root_mean_squared_error: 0.0132\n",
      "Epoch 5/10\n",
      "\n",
      "Epoch 00005: saving model to jobdir_time\\cp-0005.h5\n",
      "193367/193367 - 27s - loss: 2.4208e-04 - root_mean_squared_error: 0.0156 - val_loss: 2.4244e-04 - val_root_mean_squared_error: 0.0156\n",
      "Epoch 6/10\n",
      "\n",
      "Epoch 00006: saving model to jobdir_time\\cp-0006.h5\n",
      "193367/193367 - 28s - loss: 2.4679e-04 - root_mean_squared_error: 0.0157 - val_loss: 2.5746e-04 - val_root_mean_squared_error: 0.0160\n",
      "Epoch 7/10\n",
      "\n",
      "Epoch 00007: saving model to jobdir_time\\cp-0007.h5\n",
      "193367/193367 - 27s - loss: 2.3901e-04 - root_mean_squared_error: 0.0155 - val_loss: 1.7241e-04 - val_root_mean_squared_error: 0.0131\n",
      "Epoch 8/10\n",
      "\n",
      "Epoch 00008: saving model to jobdir_time\\cp-0008.h5\n",
      "193367/193367 - 26s - loss: 2.2965e-04 - root_mean_squared_error: 0.0152 - val_loss: 1.8972e-04 - val_root_mean_squared_error: 0.0138\n",
      "Epoch 9/10\n",
      "\n",
      "Epoch 00009: saving model to jobdir_time\\cp-0009.h5\n",
      "193367/193367 - 26s - loss: 3.1010e-04 - root_mean_squared_error: 0.0176 - val_loss: 1.8394e-04 - val_root_mean_squared_error: 0.0136\n",
      "Epoch 10/10\n",
      "\n",
      "Epoch 00010: saving model to jobdir_time\\cp-0010.h5\n",
      "193367/193367 - 27s - loss: 2.2915e-04 - root_mean_squared_error: 0.0151 - val_loss: 1.7690e-04 - val_root_mean_squared_error: 0.0133\n"
     ]
    }
   ],
   "source": [
    "history, lstm_model = run(removeall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29cc9c20d48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x29cc9ff7cc8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained LSTM for event testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = lstm_model.predict_classes(x_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ohe = np.array([[0] * len(unique_training_events) for pred_class in y_pred_class])\n",
    "for idx, class_pred in enumerate(y_pred_class):\n",
    "    y_pred_ohe[idx, class_pred] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8448236204336825"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "accuracy = accuracy_score(y_test, y_pred_ohe)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.ravel(onehot_encoder_event.inverse_transform(y_pred_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         A_PARTLYSUBMITTED\n",
       "1        W_Afhandelen leads\n",
       "2                       NaN\n",
       "3         A_PARTLYSUBMITTED\n",
       "4        W_Afhandelen leads\n",
       "                ...        \n",
       "38039    W_Afhandelen leads\n",
       "38040    W_Afhandelen leads\n",
       "38096            A_DECLINED\n",
       "38099    W_Afhandelen leads\n",
       "38100                   NaN\n",
       "Name: predicted_next_event_lstm, Length: 47823, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['predicted_next_event_lstm'] = y_pred.tolist()\n",
    "df_test['predicted_next_event_lstm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7906028480020074"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained LSTM for time testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lstm_model.predict(x_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113119.6451562069"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from math import sqrt\n",
    "inverse_y_test = time_to_next_scaler.inverse_transform(y_test)\n",
    "inverse_y_pred = time_to_next_scaler.inverse_transform(y_pred)\n",
    "rmse = sqrt(mean_squared_error(inverse_y_test, inverse_y_pred))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_next_scaler.inverse_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 8212."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Or visualise using Tensorboard\n",
    "%tensorboard --logdir jobdir/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case concept:name</th>\n",
       "      <th>eventID</th>\n",
       "      <th>case REG_DATE</th>\n",
       "      <th>case AMOUNT_REQ</th>\n",
       "      <th>event concept:name</th>\n",
       "      <th>event lifecycle:transition</th>\n",
       "      <th>event time:timestamp</th>\n",
       "      <th>unix_abs_event_time</th>\n",
       "      <th>unix_reg_time</th>\n",
       "      <th>unix_rel_event_time</th>\n",
       "      <th>actual_time_to_next_event</th>\n",
       "      <th>naive_predicted_time_to_next_event</th>\n",
       "      <th>actual_next_event</th>\n",
       "      <th>naive_predicted_next_event</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173688</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-10-01T00:38:44.546+02:00</td>\n",
       "      <td>20000</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>01-10-2011 00:38:44.546</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.585379</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173688</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-10-01T00:38:44.546+02:00</td>\n",
       "      <td>20000</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>01-10-2011 00:38:44.880</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>0.334</td>\n",
       "      <td>53.026</td>\n",
       "      <td>35.050805</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173688</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-10-01T00:38:44.546+02:00</td>\n",
       "      <td>20000</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>01-10-2011 00:39:37.906</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>53.360</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.503153</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173688</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-10-01T00:38:44.546+02:00</td>\n",
       "      <td>20000</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>01-10-2011 00:39:38.875</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>54.329</td>\n",
       "      <td>39427.562</td>\n",
       "      <td>60570.104101</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>173688</td>\n",
       "      <td>4</td>\n",
       "      <td>2011-10-01T00:38:44.546+02:00</td>\n",
       "      <td>20000</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>START</td>\n",
       "      <td>01-10-2011 11:36:46.437</td>\n",
       "      <td>1.317462e+09</td>\n",
       "      <td>1.317422e+09</td>\n",
       "      <td>39481.891</td>\n",
       "      <td>356.871</td>\n",
       "      <td>60570.104101</td>\n",
       "      <td>A_ACCEPTED</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193362</th>\n",
       "      <td>206318</td>\n",
       "      <td>44955422687236</td>\n",
       "      <td>2012-02-03T17:07:38.334+01:00</td>\n",
       "      <td>5000</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>03-02-2012 17:55:57.294</td>\n",
       "      <td>1.328288e+09</td>\n",
       "      <td>1.328285e+09</td>\n",
       "      <td>2898.960</td>\n",
       "      <td>3.704</td>\n",
       "      <td>1.955021</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193363</th>\n",
       "      <td>206318</td>\n",
       "      <td>44955422687237</td>\n",
       "      <td>2012-02-03T17:07:38.334+01:00</td>\n",
       "      <td>5000</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>03-02-2012 17:56:00.998</td>\n",
       "      <td>1.328288e+09</td>\n",
       "      <td>1.328285e+09</td>\n",
       "      <td>2902.664</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7928.199106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193364</th>\n",
       "      <td>206321</td>\n",
       "      <td>44959717654528</td>\n",
       "      <td>2012-02-03T17:08:39.199+01:00</td>\n",
       "      <td>2000</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>03-02-2012 17:08:39.200</td>\n",
       "      <td>1.328285e+09</td>\n",
       "      <td>1.328285e+09</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.585379</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193365</th>\n",
       "      <td>206321</td>\n",
       "      <td>44959717654529</td>\n",
       "      <td>2012-02-03T17:08:39.199+01:00</td>\n",
       "      <td>2000</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>03-02-2012 17:08:39.459</td>\n",
       "      <td>1.328285e+09</td>\n",
       "      <td>1.328285e+09</td>\n",
       "      <td>0.259</td>\n",
       "      <td>39.653</td>\n",
       "      <td>35.050805</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193366</th>\n",
       "      <td>206321</td>\n",
       "      <td>44959717654530</td>\n",
       "      <td>2012-02-03T17:08:39.199+01:00</td>\n",
       "      <td>2000</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>03-02-2012 17:09:19.112</td>\n",
       "      <td>1.328285e+09</td>\n",
       "      <td>1.328285e+09</td>\n",
       "      <td>39.912</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.955021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193367 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case concept:name        eventID                   case REG_DATE  \\\n",
       "0                  173688               0  2011-10-01T00:38:44.546+02:00   \n",
       "1                  173688               1  2011-10-01T00:38:44.546+02:00   \n",
       "2                  173688               2  2011-10-01T00:38:44.546+02:00   \n",
       "3                  173688               3  2011-10-01T00:38:44.546+02:00   \n",
       "4                  173688               4  2011-10-01T00:38:44.546+02:00   \n",
       "...                   ...             ...                            ...   \n",
       "193362             206318  44955422687236  2012-02-03T17:07:38.334+01:00   \n",
       "193363             206318  44955422687237  2012-02-03T17:07:38.334+01:00   \n",
       "193364             206321  44959717654528  2012-02-03T17:08:39.199+01:00   \n",
       "193365             206321  44959717654529  2012-02-03T17:08:39.199+01:00   \n",
       "193366             206321  44959717654530  2012-02-03T17:08:39.199+01:00   \n",
       "\n",
       "        case AMOUNT_REQ      event concept:name event lifecycle:transition  \\\n",
       "0                 20000             A_SUBMITTED                   COMPLETE   \n",
       "1                 20000       A_PARTLYSUBMITTED                   COMPLETE   \n",
       "2                 20000           A_PREACCEPTED                   COMPLETE   \n",
       "3                 20000  W_Completeren aanvraag                   SCHEDULE   \n",
       "4                 20000  W_Completeren aanvraag                      START   \n",
       "...                 ...                     ...                        ...   \n",
       "193362             5000              A_DECLINED                   COMPLETE   \n",
       "193363             5000      W_Afhandelen leads                   COMPLETE   \n",
       "193364             2000             A_SUBMITTED                   COMPLETE   \n",
       "193365             2000       A_PARTLYSUBMITTED                   COMPLETE   \n",
       "193366             2000              A_DECLINED                   COMPLETE   \n",
       "\n",
       "           event time:timestamp  unix_abs_event_time  unix_reg_time  \\\n",
       "0       01-10-2011 00:38:44.546         1.317422e+09   1.317422e+09   \n",
       "1       01-10-2011 00:38:44.880         1.317422e+09   1.317422e+09   \n",
       "2       01-10-2011 00:39:37.906         1.317422e+09   1.317422e+09   \n",
       "3       01-10-2011 00:39:38.875         1.317422e+09   1.317422e+09   \n",
       "4       01-10-2011 11:36:46.437         1.317462e+09   1.317422e+09   \n",
       "...                         ...                  ...            ...   \n",
       "193362  03-02-2012 17:55:57.294         1.328288e+09   1.328285e+09   \n",
       "193363  03-02-2012 17:56:00.998         1.328288e+09   1.328285e+09   \n",
       "193364  03-02-2012 17:08:39.200         1.328285e+09   1.328285e+09   \n",
       "193365  03-02-2012 17:08:39.459         1.328285e+09   1.328285e+09   \n",
       "193366  03-02-2012 17:09:19.112         1.328285e+09   1.328285e+09   \n",
       "\n",
       "        unix_rel_event_time  actual_time_to_next_event  \\\n",
       "0                     0.000                      0.334   \n",
       "1                     0.334                     53.026   \n",
       "2                    53.360                      0.969   \n",
       "3                    54.329                  39427.562   \n",
       "4                 39481.891                    356.871   \n",
       "...                     ...                        ...   \n",
       "193362             2898.960                      3.704   \n",
       "193363             2902.664                      0.000   \n",
       "193364                0.000                      0.259   \n",
       "193365                0.259                     39.653   \n",
       "193366               39.912                      0.000   \n",
       "\n",
       "        naive_predicted_time_to_next_event       actual_next_event  \\\n",
       "0                                 0.585379       A_PARTLYSUBMITTED   \n",
       "1                                35.050805           A_PREACCEPTED   \n",
       "2                                 0.503153  W_Completeren aanvraag   \n",
       "3                             60570.104101  W_Completeren aanvraag   \n",
       "4                             60570.104101              A_ACCEPTED   \n",
       "...                                    ...                     ...   \n",
       "193362                            1.955021      W_Afhandelen leads   \n",
       "193363                         7928.199106                     NaN   \n",
       "193364                            0.585379       A_PARTLYSUBMITTED   \n",
       "193365                           35.050805              A_DECLINED   \n",
       "193366                            1.955021                     NaN   \n",
       "\n",
       "       naive_predicted_next_event  day  hour  \n",
       "0               A_PARTLYSUBMITTED   10     0  \n",
       "1              W_Afhandelen leads   10     0  \n",
       "2          W_Completeren aanvraag   10     0  \n",
       "3          W_Completeren aanvraag   10     0  \n",
       "4          W_Completeren aanvraag   10    11  \n",
       "...                           ...  ...   ...  \n",
       "193362         W_Afhandelen leads    2    17  \n",
       "193363         W_Afhandelen leads    2    17  \n",
       "193364          A_PARTLYSUBMITTED    2    17  \n",
       "193365         W_Afhandelen leads    2    17  \n",
       "193366         W_Afhandelen leads    2    17  \n",
       "\n",
       "[193367 rows x 16 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
